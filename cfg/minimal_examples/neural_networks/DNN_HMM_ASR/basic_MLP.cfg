[global]
    feature_computations=$feature_computations
[/global]

[functions]    

	[compute_features]
	    class_name=speechbrain.core.execute_computations 
            cfg_file=$feature_computations
 	    torch_no_grad=True
	[/compute_features]

	[mean_var_norm]
	    class_name=speechbrain.processing.features.mean_var_norm
	    norm_type=global
            torch_no_grad=True
	[/mean_var_norm]
	    
        [linear1]
	    class_name=speechbrain.nnet.architectures.linear
	    n_neurons=1024
            bias = False
    	[/linear1]


        [activation]
	    class_name=speechbrain.nnet.architectures.activation
            act_type=leaky_relu
    	[/activation]

	[linear2]
		class_name=speechbrain.nnet.architectures.linear
		n_neurons=43
		bias=False
	[/linear2]


	[softmax]
		class_name=speechbrain.nnet.architectures.activation
		act_type=log_softmax
	[/softmax]

    	[compute_cost]
	    class_name=speechbrain.nnet.losses.compute_cost
	    cost_type=nll,error
    	[/compute_cost]

    	[optimizer]
	    class_name=speechbrain.nnet.optimizers.optimize
	    recovery=True
	    optimizer_type=adam
	    learning_rate=$lr
    	[/optimizer]

    	[print_predictions]
	    class_name=speechbrain.data_io.data_io.print_predictions
            ind2lab=ali
            output_file=$output_folder/predictions.txt
    	[/print_predictions]



[/functions]


[computations]
 
    id,wav,wav_len, ali,ali_len,batch_id,loop_id,mode,*_=get_input_var()
      
    feats=compute_features(wav)
    feats = mean_var_norm(feats,wav_len)

    out=linear1(feats)
    out=activation(out)
    out=linear2(out)
  
    pout=softmax(out)


    if mode=='valid' or mode=='train':
    	loss,error=compute_cost(pout,ali,ali_len)
    
    if mode == 'train':
        loss.backward()
        optimizer(linear1,linear2)

    if mode=='test':
        print_predictions(id,pout,wav_len)

[/computations]



